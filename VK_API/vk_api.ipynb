{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/myenv_39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import pytz\n",
    "import emoji\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "from rauth import OAuth2Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_ID=\n",
    "SECRET_KEY_VK=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_group_info(info):\n",
    "    item = {}\n",
    "\n",
    "    item['id'] = abs(info['id'])\n",
    "    item['description'] = cleaning_text(info['description']) if 'description' in info else ''\n",
    "    item['members_count'] = info['members_count'] if 'members_count' in info else 0\n",
    "    item['albums'] = info['counters']['albums'] if 'counters' in info and 'albums' in info['counters'] else 0\n",
    "    item['audios'] = info['counters']['audios'] if 'counters' in info and 'audios' in info['counters'] else 0\n",
    "    item['audio_playlists'] = info['counters']['audio_playlists'] if 'counters' in info and 'audio_playlists' in info[\n",
    "        'counters'] else 0\n",
    "    item['docs'] = info['counters']['docs'] if 'counters' in info and 'docs' in info['counters'] else 0\n",
    "    item['photos'] = info['counters']['photos'] if 'counters' in info and 'photos' in info['counters'] else 0\n",
    "    item['videos'] = info['counters']['videos'] if 'counters' in info and 'videos' in info['counters'] else 0\n",
    "    item['articles'] = info['counters']['articles'] if 'counters' in info and 'articles' in info['counters'] else 0\n",
    "    item['narratives'] = info['counters']['narratives'] if 'counters' in info and 'narratives' in info[\n",
    "        'counters'] else 0\n",
    "    item['clips'] = info['counters']['clips'] if 'counters' in info and 'clips' in info['counters'] else 0\n",
    "    item['clips_followers'] = info['counters']['clips_followers'] if 'counters' in info and 'clips_followers' in info[\n",
    "        'counters'] else 0\n",
    "    item['site'] = info['site'] if 'site' in info else ''\n",
    "    item['name'] = cleaning_text(info['name']) if 'name' in info else ''\n",
    "    item['screen_name'] = info['screen_name']\n",
    "    item['is_closed'] = info['is_closed']\n",
    "    item['type'] = info['type']\n",
    "    item['country'] = info['country']['title'] if 'country' in info and 'title' in info['country'] else ''\n",
    "    if not item['country']:\n",
    "        item['country'] = info['addresses']['main_address']['country']['title'] if 'addresses' in info and \\\n",
    "                                                                                   'main_address' in info[\n",
    "                                                                                       'addresses'] and 'address' in \\\n",
    "                                                                                   info['addresses'][\n",
    "                                                                                       'main_address'] and 'country' in \\\n",
    "                                                                                   info['addresses'][\n",
    "                                                                                       'main_address'] else ''\n",
    "    item['city'] = info['city']['title'] if 'city' in info and 'title' in info['city'] else ''\n",
    "    if not item['city']:\n",
    "        item['city'] = info['addresses']['main_address']['city']['title'] if 'addresses' in info and \\\n",
    "                                                                             'main_address' in info[\n",
    "                                                                                 'addresses'] and 'address' in \\\n",
    "                                                                             info['addresses'][\n",
    "                                                                                 'main_address'] and 'city' in \\\n",
    "                                                                             info['addresses']['main_address'] else ''\n",
    "    item['address'] = info['addresses']['main_address']['address'] if 'addresses' in info and 'main_address' in info[\n",
    "        'addresses'] and 'address' in info['addresses']['main_address'] else ''\n",
    "\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_group_post(post):\n",
    "    item = {}\n",
    "    item['donut'] = int(post['donut']['is_donut'])\n",
    "    item['comments'] = post['comments']['count'] if 'comments' in post else 0\n",
    "    item['marked_as_ads'] = post['marked_as_ads']\n",
    "    item['short_text_rate'] = post['short_text_rate']\n",
    "    item['type'] = post['type']\n",
    "\n",
    "    item['date'] = datetime.fromtimestamp(post['date'], tz=pytz.timezone('Europe/Moscow'))\n",
    "    item['from_id'] = abs(post['from_id'])\n",
    "\n",
    "    item['id'] = int(post['id'])\n",
    "    item['is_favorite'] = int(post['is_favorite'])\n",
    "    item['likes'] = post['likes']['count'] if 'likes' in post else 0\n",
    "    item['owner_id'] = abs(int(post['owner_id']))\n",
    "    item['post_source'] = post['post_source']['type'] if 'post_source' in post else ''\n",
    "    item['post_type'] = post['post_type']\n",
    "    item['reposts'] = post['reposts']['count']\n",
    "    item['user_reposted'] = post['reposts']['user_reposted']\n",
    "    item['post_text'] = cleaning_text(post['text'])\n",
    "    item['views'] = post['views']['count'] if 'views' in post else 0\n",
    "\n",
    "    attachments = parse_attachments(post)\n",
    "\n",
    "    return item, attachments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_url_photo(atts):\n",
    "    url = ''\n",
    "    if 'sizes' in atts:\n",
    "        max_width = max(list(map(lambda x: x['width'], atts['sizes'])))\n",
    "        big_size = list(filter(lambda x: x['width'] == max_width, atts['sizes']))\n",
    "        if big_size:\n",
    "            url = big_size[0]['url']\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_attachments(post):\n",
    "    items = []\n",
    "    for attachment in post['attachments']:\n",
    "        _type = attachment['type']\n",
    "        _url = ''\n",
    "\n",
    "        item = {'type': _type}\n",
    "\n",
    "        if _type in ['photo', 'doc']:\n",
    "            item['id'] = attachment[_type]['id']\n",
    "            item['owner_id'] = abs(int(attachment[_type]['owner_id']))\n",
    "            item['title'] = cleaning_text(attachment[_type]['title']) if 'title' in attachment[_type] else ''\n",
    "            item['post_id'] = int(post['id'])\n",
    "            item['date'] = datetime.fromtimestamp(attachment[_type]['date'], tz=pytz.timezone('Europe/Moscow'))\n",
    "\n",
    "            if _type == 'photo':\n",
    "\n",
    "                item['album_id'] = abs(int(attachment[_type]['album_id']))\n",
    "                item['text'] = cleaning_text(attachment[_type]['text'])\n",
    "\n",
    "                item['has_tags'] = int(attachment[_type]['has_tags'])\n",
    "                _url = parse_url_photo(attachment[_type])\n",
    "\n",
    "            elif _type == 'doc':\n",
    "                if attachment[_type]['type'] == 1:\n",
    "                    _url = attachment[_type]['url']\n",
    "\n",
    "            item['url'] = _url\n",
    "\n",
    "            items.append(item)\n",
    "    return items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_post_comments(comments, post_id, owner_id):\n",
    "    item = {\n",
    "        'id': comments['id'], 'from_id': abs(comments['from_id']),\n",
    "        'date': datetime.fromtimestamp(comments['date'], tz=pytz.timezone('Europe/Moscow')),\n",
    "        'text': cleaning_text(comments['text']), 'post_id': post_id, 'owner_id': abs(owner_id),\n",
    "        'count_likes': comments['likes']['count'] if 'likes' in comments else 0,\n",
    "        'reply_user': abs(comments['reply_to_user']) if 'reply_to_user' in comments else None,\n",
    "        'reply_comment': comments['reply_to_comment'] if 'reply_to_comment' in comments else None,\n",
    "        'parents_stack': ','.join(\n",
    "            str(x) for x in comments['parents_stack']) if 'parents_stack' in comments else None}\n",
    "\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_users(user_info):\n",
    "    item = {'user_id': user_info['id']}\n",
    "\n",
    "    item['age'] = 0\n",
    "    if 'bdate' in user_info:\n",
    "        dt = user_info['bdate'].split(\".\")\n",
    "\n",
    "        if len(dt) > 2:\n",
    "            date = datetime(int(dt[2]), int(dt[1]), int(dt[0]))\n",
    "            item['age'] = datetime.now().year - date.year\n",
    "\n",
    "    item['education'] = 0\n",
    "    if 'universities' in user_info and user_info['universities']:\n",
    "        item['education'] = 3 if user_info['universities'][0]['id'] else 0\n",
    "\n",
    "    elif 'schools' in user_info:\n",
    "        item['education'] = 1\n",
    "        if user_info['schools'] and 'type' in user_info['schools'][0]:\n",
    "            item['education'] = 1 if user_info['schools'][0]['type'] <= 4 else 2\n",
    "\n",
    "    item['sex'] = user_info['sex'] if 'sex' in user_info else 0\n",
    "    item['country'] = user_info['country']['title'] if 'country' in user_info and 'title' in user_info[\n",
    "        'country'] else ''\n",
    "    item['city'] = user_info['city']['title'] if 'city' in user_info and 'title' in user_info['city'] else ''\n",
    "    item['home_town'] = user_info['home_town'] if 'home_town' in user_info else ''\n",
    "    item['friends'] = user_info['counters']['friends'] if 'counters' in user_info and 'friends' in user_info[\n",
    "        'counters'] else 0\n",
    "    item['albums'] = user_info['counters']['albums'] if 'counters' in user_info and 'albums' in user_info[\n",
    "        'counters'] else 0\n",
    "    item['audios'] = user_info['counters']['audios'] if 'counters' in user_info and 'audios' in user_info[\n",
    "        'counters'] else 0\n",
    "    item['followers'] = user_info['counters']['followers'] if 'counters' in user_info and 'followers' in user_info[\n",
    "        'counters'] else 0\n",
    "    item['gifts'] = user_info['counters']['gifts'] if 'counters' in user_info and 'gifts' in user_info[\n",
    "        'counters'] else 0\n",
    "    item['pages'] = user_info['counters']['pages'] if 'counters' in user_info and 'pages' in user_info[\n",
    "        'counters'] else 0\n",
    "    item['photos'] = user_info['counters']['photos'] if 'counters' in user_info and 'photos' in user_info[\n",
    "        'counters'] else 0\n",
    "    item['subscriptions'] = user_info['counters']['subscriptions'] if 'counters' in user_info and 'subscriptions' in \\\n",
    "                                                                      user_info['counters'] else 0\n",
    "    item['groups'] = user_info['counters']['groups'] if 'counters' in user_info and 'groups' in user_info[\n",
    "        'counters'] else 0\n",
    "    item['videos'] = user_info['counters']['videos'] if 'counters' in user_info and 'videos' in user_info[\n",
    "        'counters'] else 0\n",
    "\n",
    "    item['about'] = cleaning_text(user_info['about']) if 'about' in user_info else ''\n",
    "    item['status'] = cleaning_text(user_info['status']) if 'status' in user_info else ''\n",
    "    item['pages_list'] = ','.join(str(x) for x in user_info['users']['items']) if 'users' in user_info and \\\n",
    "                                                                                  user_info['users']['items'] else ''\n",
    "    item['groups_list'] = ','.join(str(x) for x in user_info['groups']['items']) if 'groups' in user_info and \\\n",
    "                                                                                    user_info['groups'][\n",
    "                                                                                        'items'] else ''\n",
    "\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(string):\n",
    "    emoticon_string = r\"\"\"\n",
    "            (?:\n",
    "              [<>]?\n",
    "              [:;=8]                     # eyes\n",
    "              [\\-o\\*\\']?                 # optional nose\n",
    "              [\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\] # mouth      \n",
    "              |\n",
    "              [\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\] # mouth\n",
    "              [\\-o\\*\\']?                 # optional nose\n",
    "              [:;=8]                     # eyes\n",
    "              [<>]?\n",
    "            )\"\"\"\n",
    "\n",
    "    # remove graf emoji\n",
    "    string = emoji.replace_emoji(string, r'')\n",
    "\n",
    "    # remove [id text]\n",
    "    string = re.sub(r'\\[id[^()]*\\]', '', string)\n",
    "\n",
    "    # remove [club text]\n",
    "    string = re.sub(r'\\[club[^()]*\\]', '', string)\n",
    "\n",
    "    # remove links and all except [^А-я0-9.,!?ё ] and '\\n'\n",
    "    string = re.sub(\"[^ ]+\\.[^ ]+\", '', re.sub(r\"[^А-я0-9.,!?ё ]\", ' ', string.replace('\\n', ' ')))\n",
    "\n",
    "    # remove duplicate\n",
    "    string = re.sub(r'!+', '!', string)\n",
    "    string = re.sub(r'\\?+', '?', string)\n",
    "    string = re.sub('[.]+', '.', string)\n",
    "    string = re.sub(r'\\s+', ' ', string)\n",
    "\n",
    "    string = string.lstrip(',./\";:)}({<>!?@#$%^&*_+').strip()\n",
    "\n",
    "    if not re.search('[а-яА-Я]', string):\n",
    "        string = ''\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_info(domains):\n",
    "    res_group_info = []\n",
    "    group_info = []\n",
    "    data = {'group_ids': ','.join(str(x) for x in domains)}\n",
    "\n",
    "    fields = {\n",
    "        'fields': 'id,name,screen_name,type,counters,description,fixed_post,links,members_count,site,wiki_page,counters,country,contacts, addresses'}\n",
    "\n",
    "    response = requests.post('https://api.vk.com/method/groups.getById', data=data | params | fields)\n",
    "\n",
    "    if 'response' in response.json():\n",
    "        group_response = response.json().get('response')\n",
    "        for group_item in group_response:\n",
    "            group_info = parse_group_info(group_item)\n",
    "\n",
    "            res_group_info.append(group_info)\n",
    "\n",
    "    if 'error' in response.json():\n",
    "        error = response.json().get('error')\n",
    "        print(error)\n",
    "\n",
    "    return res_group_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_posts(domain):\n",
    "    uploaded_posts = []\n",
    "    uploaded_attachments = []\n",
    "    offset = 0\n",
    "    count = 100\n",
    "\n",
    "    data = {'domain': domain, 'filter': str('owner')}\n",
    "    pbar = tqdm(desc='POSTS')\n",
    "\n",
    "    while True:\n",
    "\n",
    "        data['offset'] = offset\n",
    "        data['count'] = count\n",
    "\n",
    "        response = requests.post('https://api.vk.com/method/wall.get', data=data | params)\n",
    "        sleep(0.2)\n",
    "\n",
    "        if 'response' in response.json():\n",
    "            group_posts = response.json().get('response')\n",
    "            items = None\n",
    "\n",
    "            if group_posts:\n",
    "                items = group_posts['items']\n",
    "                pbar.total = group_posts['count']\n",
    "                offset = offset + len(items)\n",
    "                pbar.update(len(items))\n",
    "\n",
    "                res = list(map(lambda item: parse_group_post(item), items))\n",
    "                uploaded_posts = uploaded_posts + list(map(lambda x: x[0], res))\n",
    "                for res_attach in res:\n",
    "                    uploaded_attachments = uploaded_attachments + list(map(lambda x: x, res_attach[1]))\n",
    "\n",
    "            if not items:\n",
    "                break\n",
    "\n",
    "        if 'error' in response.json():\n",
    "            error = response.json().get('error')\n",
    "            print(error)\n",
    "\n",
    "    return uploaded_posts, uploaded_attachments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_members(group_id):\n",
    "    uploaded_members = []\n",
    "    offset = 0\n",
    "    count = 1000\n",
    "    total = 0\n",
    "\n",
    "    data = {'group_id': group_id, 'sort': 'id_asc'}\n",
    "    fields = {\n",
    "        'fields': 'bdate,city,common_count,connections,contacts,country,domain,education,last_seen,lists,relation,relatives,schools,sex,site,status,universities'}\n",
    "\n",
    "    response = requests.get('https://api.vk.com/method/groups.getMembers', data | params | fields)\n",
    "    if 'response' in response.json():\n",
    "        total = response.json().get('response')['count']\n",
    "\n",
    "    while total > offset:\n",
    "        if total - offset < count:\n",
    "            count = total - offset\n",
    "\n",
    "        data['offset'] = offset\n",
    "        data['count'] = count\n",
    "        response = requests.get('https://api.vk.com/method/groups.getMembers', data | params | fields)\n",
    "\n",
    "        items = None\n",
    "\n",
    "        if 'response' in response.json():\n",
    "            members = response.json().get('response')\n",
    "\n",
    "            if members:\n",
    "                items = members['items']\n",
    "                offset += len(items)\n",
    "                uploaded_members += items\n",
    "\n",
    "            if not items:\n",
    "                break\n",
    "        if 'error' in response.json():\n",
    "            error = response.json().get('error')\n",
    "            print(error)\n",
    "        sleep(0.1)\n",
    "\n",
    "    return uploaded_members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_info(user_id):\n",
    "    data = {'user_id': user_id}\n",
    "    fields = {'fields': 'bdate,sex,universities,education,schools,counters,about, status, city, country, home_town'}\n",
    "\n",
    "    user_response = requests.post('https://api.vk.com/method/users.get', data=data | params | fields)\n",
    "    sleep(0.2)\n",
    "    fields = {'fields': 'user, group'}\n",
    "    subs_response = requests.post('https://api.vk.com/method/users.getSubscriptions', data=data | params | fields)\n",
    "    sleep(0.2)\n",
    "\n",
    "    if 'response' in user_response.json():\n",
    "        subscriptions = subs_response.json().get('response') if 'response' in subs_response.json() else {}\n",
    "        user_info = user_response.json().get('response')\n",
    "        if user_info:\n",
    "            user_info = user_info[0] | subscriptions\n",
    "\n",
    "            return parse_users(user_info)\n",
    "        return {}\n",
    "\n",
    "    if 'error' in user_response.json():\n",
    "        error = user_response.json().get('error')\n",
    "        print(error)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts_comments(owner_id, post_id):\n",
    "    uploaded_comments = []\n",
    "    offset = 0\n",
    "    count = 100\n",
    "\n",
    "    data = {'owner_id': -int(owner_id), 'post_id': int(post_id), 'need_likes': 1, 'extended': 1,\n",
    "            'thread_items_count': 10}\n",
    "\n",
    "    while True:\n",
    "        data['offset'] = offset\n",
    "        data['count'] = count\n",
    "        response = requests.post('https://api.vk.com/method/wall.getComments', data=data | params)\n",
    "        sleep(0.2)\n",
    "        items = None\n",
    "\n",
    "        if 'response' in response.json():\n",
    "            comments_posts = response.json().get('response')\n",
    "\n",
    "            if comments_posts:\n",
    "                items = comments_posts['items']\n",
    "                offset = offset + len(items)\n",
    "\n",
    "                for item in items:\n",
    "                    uploaded_comments.append(parse_post_comments(item, post_id, owner_id))\n",
    "                    if 'thread' in item and item['thread']['items']:\n",
    "                        uploaded_comments += list(\n",
    "                            map(lambda x: parse_post_comments(x, post_id, owner_id), item['thread']['items']))\n",
    "\n",
    "            if not items:\n",
    "                break\n",
    "        if 'error' in response.json():\n",
    "            error = response.json().get('error')\n",
    "            print(error)\n",
    "    return uploaded_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages_and_groups_info(df_list):\n",
    "    df = pd.concat(df_list)\n",
    "    df = df[['pages_list', 'groups_list']]\n",
    "\n",
    "    groups_list = []\n",
    "\n",
    "    for mm in df.itertuples():\n",
    "        if pd.notna(mm.pages_list) and mm.pages_list:\n",
    "            p_list = str(mm.pages_list).split(',')\n",
    "            groups_list += p_list\n",
    "        if pd.notna(mm.groups_list) and mm.groups_list:\n",
    "            g_list = str(mm.groups_list).split(',')\n",
    "            groups_list += g_list\n",
    "\n",
    "    groups_list = list(map(lambda x: int(x), groups_list))\n",
    "\n",
    "    groups_info = []\n",
    "    g_items = pd.Series(groups_list).unique().tolist()\n",
    "\n",
    "    total = 0\n",
    "    offset = 500\n",
    "    pbar = tqdm(desc='groups info', total=len(g_items))\n",
    "    while len(g_items) > total:\n",
    "        if len(g_items) - total < 500:\n",
    "            offset = len(g_items) - total\n",
    "        groups_info = groups_info + get_group_info(g_items[total:offset + total])\n",
    "        pbar.update(offset)\n",
    "        total += offset\n",
    "    return groups_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_token(APP_ID, SECRET_KEY_VK):\n",
    "    if os.getenv('TOKEN_VK'):\n",
    "        return os.environ[\"TOKEN_VK\"]\n",
    "    # создание объекта сервиса OAuth2\n",
    "    service = OAuth2Service(\n",
    "        client_id=APP_ID,\n",
    "        client_secret=SECRET_KEY_VK,\n",
    "        name='vk',\n",
    "        authorize_url='https://oauth.vk.com/authorize',\n",
    "        access_token_url='https://oauth.vk.com/access_token',\n",
    "        base_url='https://api.vk.com/method/'\n",
    "    )\n",
    "\n",
    "    # получение ссылки на авторизацию\n",
    "    params = {'scope': 'photos,wall,friends, email, offline, groups'}\n",
    "    url = service.get_authorize_url(**params)\n",
    "\n",
    "    # переход на страницу авторизации\n",
    "    print(f'Перейдите по этой ссылке и разрешите доступ: {url}')\n",
    "    redirect_url = input('Введите URL перенаправления: ')\n",
    "\n",
    "    # получение токена\n",
    "    oauth_session = service.get_raw_access_token(\n",
    "        data={'code': redirect_url.split('code=')[1],\n",
    "              'client_id': APP_ID,\n",
    "              'client_secret': SECRET_KEY_VK, },\n",
    "    )\n",
    "    user_id = oauth_session.json().get('user_id')\n",
    "    token = oauth_session.json().get('access_token')\n",
    "\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_excel(df, name, domain):\n",
    "    if 'date' in df:\n",
    "        df['date'] = df['date'].apply(lambda a: pd.to_datetime(a).date())\n",
    "\n",
    "    path = f'storage/output/{domain}'\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "    df.to_excel(f'{path}/{domain}_{name}.xlsx', sheet_name=name)\n",
    "\n",
    "    print(f'saving the {domain}_{name}.xlsx file is done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(domain):\n",
    "    # group info\n",
    "    res_group_info = get_group_info([domain])\n",
    "    #print(res_group_info)\n",
    "    df_group_info = pd.DataFrame(res_group_info)\n",
    "    group_id = res_group_info[0]['id']\n",
    "    save_to_excel(domain=domain, name='info', df=df_group_info)\n",
    "    \n",
    "    '''\n",
    "    # posts\n",
    "    res_group_posts = get_group_posts(domain)\n",
    "    df_posts = pd.DataFrame(res_group_posts[0])\n",
    "    save_to_excel(domain=domain, name='posts', df=df_posts)\n",
    "    #print(res_group_posts)\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    # post attachments\n",
    "    df_attachments = pd.DataFrame(res_group_posts[1])\n",
    "    save_to_excel(domain=domain, name='attachments_post', df=df_attachments)\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    # posts comments\n",
    "    res_posts_comments = []\n",
    "    for post in tqdm(df_posts.itertuples(), total=len(df_posts), desc='COMMENTS'):\n",
    "        res_posts_comments = res_posts_comments + get_posts_comments(post.owner_id, post.id)\n",
    "    df_comments = pd.DataFrame(res_posts_comments)\n",
    "    save_to_excel(domain=domain, name='comments', df=df_comments)    \n",
    "    '''\n",
    "    '''\n",
    "    # members info\n",
    "    res_group_members = get_group_members(group_id)\n",
    "    res_members = pd.DataFrame(res_group_members).drop_duplicates(subset=['id'])\n",
    "    # save_to_excel(domain=domain, name='group_members_raw', df=res_members)\n",
    "    res_members_info = []\n",
    "    for user in tqdm(res_members['id'].tolist(), desc='MEMBERS'):\n",
    "        members_info = get_user_info(user)\n",
    "        if members_info:\n",
    "            item_user = {'group_id': group_id} | members_info\n",
    "            res_members_info.append(item_user)\n",
    "    df_members = pd.DataFrame(res_members_info)\n",
    "    save_to_excel(domain=domain, name='members', df=df_members)\n",
    "    '''\n",
    "    '''\n",
    "    # users info from comments\n",
    "    #df_comments = pd.read_excel('storage/output/sikhotezap/sikhotezap_comments.xlsx')\n",
    "    df_comments = df_comments[['from_id', 'owner_id']].drop_duplicates().reset_index(drop=True)\n",
    "    res_users_from_comments = []\n",
    "    for comment in tqdm(df_comments.itertuples(), total=len(df_comments), desc='USERS FROM COMMENTS'):\n",
    "        user_info = get_user_info(comment.from_id)\n",
    "        if user_info:\n",
    "            item_user = {'group_id': comment.owner_id} | user_info\n",
    "            res_users_from_comments.append(item_user)\n",
    "    df_users_from_comments = pd.DataFrame(res_users_from_comments)\n",
    "    save_to_excel(domain=domain, name='users_from_comments', df=df_users_from_comments)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vk1.a.5ZbWLF-CiwHBEJE4uWL1x1_LbF6dYFFHKtwSPQ3ZIHP2nQLq0gKDREJs0ubgKVB_3KS5WNwLzOtbGA53vD-KGBRRCbD0KWcyK0PpXk4YJ6FMu2YTRI5BpVN1Wzvmsa1KZsrfcsX05rhfwjhpGRGVj0eyTYOugq-peTSp6GDkpH0jBumx86eJEQI4ZPmfLDLXowjniDT8D1YQCUs960HYYQ\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKEN_VK\"] = ''\n",
    "os.environ[\"TOKEN_VK\"] = get_user_token(APP_ID, SECRET_KEY_VK)\n",
    "params = {'v': '5.131', 'access_token': os.environ[\"TOKEN_VK\"]}\n",
    "print(os.environ[\"TOKEN_VK\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the sikhotezap_info.xlsx file is done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MEMBERS: 100%|██████████████████████████████| 2170/2170 [28:44<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the sikhotezap_members.xlsx file is done\n"
     ]
    }
   ],
   "source": [
    "run('sikhotezap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "myenv_39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
